===== Load balancing and HTTP Checks ======
Nearly all load balancers worth using have some functionality for checking at least the availability of the various backends they service. Often these checks simply verify that the correct port is open on the backend host. Some load balancers, including those servicing xCloud, have the ability to do advanced backend health checks sending for instance an HTTP request and validating the response. See [[xcloud:load_balancer|xCloud Load Balancer]] for more information. This document discusses the role of HTTP checks from a load balancer perspective with the intent of helping you determine whether you want to use them for your application.

==== Assumptions ====
We're going to assume a typical 3 tier application setup with the xCloud load balancer at the top distributing incoming //connections// to backend hosts. Below this sits nginx, haproxy, or some combination of load balancers designed to distribute //requests//. The requests ultimately reach an application server (mongrel, thin, unicorn, passenger instances, etc).

==== What's wrong with TCP Checks? ====
The big drawback of TCP checks is they are not strictly 'health' checks. It's entirely possible for an application server to be listening on a TCP port but not actually be able to serve traffic. Some common causes: restarting application instance (mongrel tends to open ports before the app is totally up), missing runtime dependencies, database failures, or the app instance being swapped out to disk. TCP checks tend to be an 80% solution, they do a good but not great job of verifying applications are up. Combined with a spinup delay so that requests are deferred while the app instances start up they can be even more effective. 

==== Can HTTP checks help? ====
HTTP checks could be a benefit or a detriment depending on how they are deployed. HTTP checks use substantially more resources than a TCP check. In the case of a single threaded application they will very likely tie up that instance. This is extremely important as too frequent HTTP checks can generate substantial load on an application. Assuming 20 app instances with checks every 5 seconds that totals 240 RPM. That's 240 fewer client requests per minute that your app can handle at peak load, and the overall RPM used for monitoring only grows with an increasing number of application instances.

=== What if I only do http checks from the xCloud load balancer? ===
If you use TCP checks at the nginx layer and HTTP checks from the connection ie xCloud load balancer you reduce the application load due to monitoring substantially. Unfortunately this method is also prone to false positives. Under heavy load monitoring requests from the load balancer could get stacked up behind legitimate requests, ultimately timing out and causing hosts to be dropped from the load balancing pool. Under heavy load this has a cascading effect that could take the entire site offline.

==== Should I use HTTP Checks? ====
For single threaded rails apps you should consider sticking with TCP checks and relying on the application to gracefully handle issues such as database and external API failures. If you must use HTTP checks with a single threaded app you might consider writing a bare rack/thin/mongrel handler that can sit outside of your rails application mutex and handle status requests performing some basic database or other tests before returning a successful status.